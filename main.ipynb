{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shu26/DCGAN_pytorch/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "GomqlrXR74vp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86b4f930-4fd5-466b-cd69-a1378330bb39"
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "     print('ok')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UW-X7zte8BMl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7424
        },
        "outputId": "a4ed7426-3ea2-496c-f901-401c4c585518"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "\n",
        "batchSize=100\n",
        "imageSize=64\n",
        "nz=100\n",
        "ngf=32\n",
        "ndf=32\n",
        "niter=1001\n",
        "cuda=True\n",
        "ngpu=1\n",
        "opt_netG=\"\"\n",
        "opt_netD=\"\"\n",
        "outf='outf_layer5'\n",
        "nc=1\n",
        "\n",
        "try:\n",
        "    os.makedirs(outf)\n",
        "    print(\"you had made directory\")\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "if torch.cuda.is_available() and not cuda:\n",
        "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(imageSize),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dset.MNIST('data/mnist', train=True, download=True, transform=transform),\n",
        "    batch_size=batchSize, shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
        "\n",
        "\n",
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            \n",
        "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            \n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.is_cuda and self.ngpu > 1:\n",
        "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "        else:\n",
        "            output = self.main(input)\n",
        "        return output\n",
        "\n",
        "\n",
        "netG = Generator(ngpu).to(device)\n",
        "netG.apply(weights_init)\n",
        "if opt_netG != '':\n",
        "    netG.load_state_dict(torch.load(opt_netG))\n",
        "print(netG)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.is_cuda and self.ngpu > 1:\n",
        "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "        else:\n",
        "            output = self.main(input)\n",
        "\n",
        "        return output.view(-1, 1).squeeze(1)\n",
        "\n",
        "\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "netD.apply(weights_init)\n",
        "if opt_netD != '':\n",
        "    netD.load_state_dict(torch.load(opt_netD))\n",
        "print(netD)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "fixed_noise = torch.randn(batchSize, nz, 1, 1, device=device)\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "# setup optimizer\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "for epoch in range(niter):\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        # train with real\n",
        "        netD.zero_grad()\n",
        "        real_cpu = data[0].to(device)\n",
        "        batch_size = real_cpu.size(0)\n",
        "        label = torch.full((batch_size,), real_label, device=device)\n",
        "        output = netD(real_cpu)\n",
        "        errD_real = criterion(output, label)\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        # train with fake\n",
        "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        output = netD(fake.detach())\n",
        "        errD_fake = criterion(output, label)\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        errD = errD_real + errD_fake\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        output = netD(fake)\n",
        "        errG = criterion(output, label)\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
        "              % (epoch, niter, i, len(dataloader),\n",
        "                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "            vutils.save_image(real_cpu,\n",
        "                    '%s/real_samples.png' % outf,\n",
        "                    normalize=True)\n",
        "            fake = netG(fixed_noise)\n",
        "            vutils.save_image(fake.detach(),\n",
        "                    '%s/fake_samples_epoch_%03d.png' % (outf, epoch),\n",
        "                    normalize=True)\n",
        "    if epoch % 1 == 0:\n",
        "        fake = netG(fixed_noise)\n",
        "        vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png'\n",
        "                              % ('results_100_lr', epoch),normalize=True)\n",
        "\n",
        "    # do checkpointing\n",
        "    if epoch % 10 == 0:\n",
        "        torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))\n",
        "        torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outf, epoch))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace)\n",
            "    (12): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (5): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (8): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (11): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n",
            "[0/1001][0/600] Loss_D: 1.4492 Loss_G: 1.7949 D(x): 0.4588 D(G(z)): 0.4189 / 0.1906\n",
            "[0/1001][100/600] Loss_D: 0.0071 Loss_G: 7.0466 D(x): 0.9973 D(G(z)): 0.0044 / 0.0010\n",
            "[0/1001][200/600] Loss_D: 0.0026 Loss_G: 7.4292 D(x): 0.9996 D(G(z)): 0.0022 / 0.0007\n",
            "[0/1001][300/600] Loss_D: 0.0015 Loss_G: 7.5323 D(x): 0.9996 D(G(z)): 0.0011 / 0.0006\n",
            "[0/1001][400/600] Loss_D: 0.0009 Loss_G: 7.8516 D(x): 0.9998 D(G(z)): 0.0006 / 0.0004\n",
            "[0/1001][500/600] Loss_D: 0.0004 Loss_G: 8.4724 D(x): 0.9999 D(G(z)): 0.0003 / 0.0002\n",
            "[1/1001][0/600] Loss_D: 0.0003 Loss_G: 8.5292 D(x): 0.9999 D(G(z)): 0.0003 / 0.0002\n",
            "[1/1001][100/600] Loss_D: 0.0002 Loss_G: 8.8403 D(x): 1.0000 D(G(z)): 0.0002 / 0.0001\n",
            "[1/1001][200/600] Loss_D: 0.0002 Loss_G: 9.2798 D(x): 0.9999 D(G(z)): 0.0001 / 0.0001\n",
            "[1/1001][300/600] Loss_D: 0.0002 Loss_G: 9.0665 D(x): 0.9999 D(G(z)): 0.0001 / 0.0001\n",
            "[1/1001][400/600] Loss_D: 0.0001 Loss_G: 9.5378 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
            "[1/1001][500/600] Loss_D: 0.0001 Loss_G: 9.8237 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
            "[2/1001][0/600] Loss_D: 0.0001 Loss_G: 9.6651 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
            "[2/1001][100/600] Loss_D: 0.0001 Loss_G: 10.1999 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[2/1001][200/600] Loss_D: 0.0000 Loss_G: 10.6812 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[2/1001][300/600] Loss_D: 0.0000 Loss_G: 10.4530 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[2/1001][400/600] Loss_D: 0.0001 Loss_G: 10.3014 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[2/1001][500/600] Loss_D: 0.0000 Loss_G: 10.2058 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[3/1001][0/600] Loss_D: 0.0000 Loss_G: 10.2000 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[3/1001][100/600] Loss_D: 0.0000 Loss_G: 10.9102 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[3/1001][200/600] Loss_D: 0.0000 Loss_G: 10.9473 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[3/1001][300/600] Loss_D: 0.0000 Loss_G: 11.2441 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[3/1001][400/600] Loss_D: 0.0000 Loss_G: 11.1573 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[3/1001][500/600] Loss_D: 0.0000 Loss_G: 11.1534 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[4/1001][0/600] Loss_D: 0.0000 Loss_G: 11.4602 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[4/1001][100/600] Loss_D: 0.0000 Loss_G: 11.9198 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[4/1001][200/600] Loss_D: 0.0000 Loss_G: 11.8140 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[4/1001][300/600] Loss_D: 0.0000 Loss_G: 12.1131 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[4/1001][400/600] Loss_D: 0.0000 Loss_G: 12.2103 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[4/1001][500/600] Loss_D: 0.0000 Loss_G: 12.2430 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[5/1001][0/600] Loss_D: 0.0000 Loss_G: 12.3673 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[5/1001][100/600] Loss_D: 0.0000 Loss_G: 12.3802 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[5/1001][200/600] Loss_D: 0.0000 Loss_G: 12.4204 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[5/1001][300/600] Loss_D: 0.0000 Loss_G: 12.4679 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[5/1001][400/600] Loss_D: 0.0000 Loss_G: 12.4554 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[5/1001][500/600] Loss_D: 0.0000 Loss_G: 12.4849 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[6/1001][0/600] Loss_D: 0.0000 Loss_G: 12.3603 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[6/1001][100/600] Loss_D: 0.0000 Loss_G: 12.4209 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[6/1001][200/600] Loss_D: 0.0000 Loss_G: 12.3086 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[6/1001][300/600] Loss_D: 0.0000 Loss_G: 12.7301 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[6/1001][400/600] Loss_D: 0.0000 Loss_G: 12.7605 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[6/1001][500/600] Loss_D: 0.0000 Loss_G: 12.9162 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[7/1001][0/600] Loss_D: 0.0000 Loss_G: 12.9545 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[7/1001][100/600] Loss_D: 0.0000 Loss_G: 13.2179 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[7/1001][200/600] Loss_D: 0.0000 Loss_G: 13.0317 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[7/1001][300/600] Loss_D: 0.0000 Loss_G: 13.1659 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[7/1001][400/600] Loss_D: 0.0000 Loss_G: 12.9792 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[7/1001][500/600] Loss_D: 0.0000 Loss_G: 12.8348 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[8/1001][0/600] Loss_D: 0.0000 Loss_G: 12.3278 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[8/1001][100/600] Loss_D: 0.0000 Loss_G: 12.5208 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[8/1001][200/600] Loss_D: 0.0000 Loss_G: 12.1357 D(x): 1.0000 D(G(z)): 0.0000 / 0.0000\n",
            "[8/1001][300/600] Loss_D: 2.4633 Loss_G: 0.7015 D(x): 0.4223 D(G(z)): 0.0810 / 0.5133\n",
            "[8/1001][400/600] Loss_D: 0.2858 Loss_G: 5.2437 D(x): 0.8873 D(G(z)): 0.1214 / 0.0080\n",
            "[8/1001][500/600] Loss_D: 0.2173 Loss_G: 3.2604 D(x): 0.8948 D(G(z)): 0.0821 / 0.0479\n",
            "[9/1001][0/600] Loss_D: 0.1486 Loss_G: 3.7629 D(x): 0.9361 D(G(z)): 0.0732 / 0.0301\n",
            "[9/1001][100/600] Loss_D: 0.0958 Loss_G: 3.9047 D(x): 0.9569 D(G(z)): 0.0481 / 0.0271\n",
            "[9/1001][200/600] Loss_D: 0.1083 Loss_G: 4.0165 D(x): 0.9629 D(G(z)): 0.0660 / 0.0232\n",
            "[9/1001][300/600] Loss_D: 0.3506 Loss_G: 2.4239 D(x): 0.8182 D(G(z)): 0.1253 / 0.1076\n",
            "[9/1001][400/600] Loss_D: 0.5640 Loss_G: 1.8564 D(x): 0.8042 D(G(z)): 0.2718 / 0.1777\n",
            "[9/1001][500/600] Loss_D: 0.6102 Loss_G: 1.5305 D(x): 0.8295 D(G(z)): 0.3123 / 0.2517\n",
            "[10/1001][0/600] Loss_D: 0.2617 Loss_G: 2.3572 D(x): 0.8489 D(G(z)): 0.0825 / 0.1116\n",
            "[10/1001][100/600] Loss_D: 0.4306 Loss_G: 3.3516 D(x): 0.9639 D(G(z)): 0.3045 / 0.0465\n",
            "[10/1001][200/600] Loss_D: 0.3356 Loss_G: 1.9002 D(x): 0.7981 D(G(z)): 0.0863 / 0.1778\n",
            "[10/1001][300/600] Loss_D: 0.8106 Loss_G: 1.2008 D(x): 0.5049 D(G(z)): 0.0209 / 0.3443\n",
            "[10/1001][400/600] Loss_D: 0.3493 Loss_G: 1.7123 D(x): 0.7945 D(G(z)): 0.0945 / 0.2193\n",
            "[10/1001][500/600] Loss_D: 0.3340 Loss_G: 2.2761 D(x): 0.8532 D(G(z)): 0.1441 / 0.1271\n",
            "[11/1001][0/600] Loss_D: 0.6690 Loss_G: 3.5572 D(x): 0.9665 D(G(z)): 0.4311 / 0.0408\n",
            "[11/1001][100/600] Loss_D: 0.4987 Loss_G: 2.5644 D(x): 0.8931 D(G(z)): 0.2909 / 0.0985\n",
            "[11/1001][200/600] Loss_D: 0.3624 Loss_G: 1.7144 D(x): 0.7983 D(G(z)): 0.0980 / 0.2306\n",
            "[11/1001][300/600] Loss_D: 1.2627 Loss_G: 1.0439 D(x): 0.3914 D(G(z)): 0.1124 / 0.3892\n",
            "[11/1001][400/600] Loss_D: 0.3913 Loss_G: 3.4177 D(x): 0.9101 D(G(z)): 0.2389 / 0.0432\n",
            "[11/1001][500/600] Loss_D: 0.3802 Loss_G: 1.3809 D(x): 0.7594 D(G(z)): 0.0703 / 0.3251\n",
            "[12/1001][0/600] Loss_D: 0.8912 Loss_G: 2.7212 D(x): 0.9135 D(G(z)): 0.4959 / 0.0916\n",
            "[12/1001][100/600] Loss_D: 0.7288 Loss_G: 1.3562 D(x): 0.6615 D(G(z)): 0.2200 / 0.3034\n",
            "[12/1001][200/600] Loss_D: 0.6528 Loss_G: 2.1014 D(x): 0.5727 D(G(z)): 0.0172 / 0.1710\n",
            "[12/1001][300/600] Loss_D: 0.3624 Loss_G: 2.1188 D(x): 0.7862 D(G(z)): 0.0904 / 0.1549\n",
            "[12/1001][400/600] Loss_D: 0.6808 Loss_G: 4.8809 D(x): 0.9822 D(G(z)): 0.4407 / 0.0126\n",
            "[12/1001][500/600] Loss_D: 0.3019 Loss_G: 2.8109 D(x): 0.8950 D(G(z)): 0.1586 / 0.0777\n",
            "[13/1001][0/600] Loss_D: 0.3888 Loss_G: 1.5834 D(x): 0.7728 D(G(z)): 0.0955 / 0.2542\n",
            "[13/1001][100/600] Loss_D: 0.5441 Loss_G: 1.2295 D(x): 0.6829 D(G(z)): 0.1122 / 0.3487\n",
            "[13/1001][200/600] Loss_D: 0.1503 Loss_G: 2.8945 D(x): 0.9140 D(G(z)): 0.0541 / 0.0791\n",
            "[13/1001][300/600] Loss_D: 0.1261 Loss_G: 3.5249 D(x): 0.9474 D(G(z)): 0.0651 / 0.0414\n",
            "[13/1001][400/600] Loss_D: 0.3669 Loss_G: 2.5622 D(x): 0.8107 D(G(z)): 0.1085 / 0.1079\n",
            "[13/1001][500/600] Loss_D: 0.3574 Loss_G: 2.2352 D(x): 0.7647 D(G(z)): 0.0568 / 0.1397\n",
            "[14/1001][0/600] Loss_D: 2.9800 Loss_G: 0.2635 D(x): 0.1049 D(G(z)): 0.0082 / 0.8065\n",
            "[14/1001][100/600] Loss_D: 0.2958 Loss_G: 4.2853 D(x): 0.9747 D(G(z)): 0.2166 / 0.0199\n",
            "[14/1001][200/600] Loss_D: 0.9069 Loss_G: 1.4392 D(x): 0.4846 D(G(z)): 0.0279 / 0.2835\n",
            "[14/1001][300/600] Loss_D: 0.4591 Loss_G: 5.4364 D(x): 0.9877 D(G(z)): 0.3283 / 0.0061\n",
            "[14/1001][400/600] Loss_D: 0.2388 Loss_G: 2.5693 D(x): 0.9246 D(G(z)): 0.1398 / 0.0946\n",
            "[14/1001][500/600] Loss_D: 0.6972 Loss_G: 3.7499 D(x): 0.9815 D(G(z)): 0.4415 / 0.0331\n",
            "[15/1001][0/600] Loss_D: 0.1859 Loss_G: 2.7728 D(x): 0.8997 D(G(z)): 0.0677 / 0.0859\n",
            "[15/1001][100/600] Loss_D: 0.5282 Loss_G: 1.2112 D(x): 0.6367 D(G(z)): 0.0111 / 0.3546\n",
            "[15/1001][200/600] Loss_D: 1.4641 Loss_G: 0.5538 D(x): 0.3277 D(G(z)): 0.0652 / 0.6280\n",
            "[15/1001][300/600] Loss_D: 0.1463 Loss_G: 4.0189 D(x): 0.9650 D(G(z)): 0.0991 / 0.0260\n",
            "[15/1001][400/600] Loss_D: 0.2370 Loss_G: 2.9212 D(x): 0.9361 D(G(z)): 0.1432 / 0.0767\n",
            "[15/1001][500/600] Loss_D: 0.1443 Loss_G: 2.9995 D(x): 0.9348 D(G(z)): 0.0687 / 0.0708\n",
            "[16/1001][0/600] Loss_D: 0.2510 Loss_G: 2.3481 D(x): 0.8096 D(G(z)): 0.0217 / 0.1338\n",
            "[16/1001][100/600] Loss_D: 0.1117 Loss_G: 3.9539 D(x): 0.9587 D(G(z)): 0.0638 / 0.0314\n",
            "[16/1001][200/600] Loss_D: 0.2201 Loss_G: 2.5551 D(x): 0.8879 D(G(z)): 0.0868 / 0.1077\n",
            "[16/1001][300/600] Loss_D: 0.3719 Loss_G: 3.0240 D(x): 0.8741 D(G(z)): 0.1884 / 0.0658\n",
            "[16/1001][400/600] Loss_D: 0.4141 Loss_G: 2.8208 D(x): 0.9062 D(G(z)): 0.2399 / 0.0796\n",
            "[16/1001][500/600] Loss_D: 0.1734 Loss_G: 3.8215 D(x): 0.9371 D(G(z)): 0.0958 / 0.0349\n",
            "[17/1001][0/600] Loss_D: 0.2315 Loss_G: 4.6612 D(x): 0.9635 D(G(z)): 0.1581 / 0.0162\n",
            "[17/1001][100/600] Loss_D: 0.2730 Loss_G: 3.6890 D(x): 0.9525 D(G(z)): 0.1855 / 0.0364\n",
            "[17/1001][200/600] Loss_D: 0.1011 Loss_G: 3.3701 D(x): 0.9410 D(G(z)): 0.0356 / 0.0499\n",
            "[17/1001][300/600] Loss_D: 0.1074 Loss_G: 3.0687 D(x): 0.9401 D(G(z)): 0.0417 / 0.0685\n",
            "[17/1001][400/600] Loss_D: 0.8025 Loss_G: 5.9989 D(x): 0.9891 D(G(z)): 0.4852 / 0.0039\n",
            "[17/1001][500/600] Loss_D: 0.2410 Loss_G: 2.3037 D(x): 0.8581 D(G(z)): 0.0632 / 0.1446\n",
            "[18/1001][0/600] Loss_D: 0.1071 Loss_G: 4.6221 D(x): 0.9853 D(G(z)): 0.0852 / 0.0147\n",
            "[18/1001][100/600] Loss_D: 1.0171 Loss_G: 1.3093 D(x): 0.4981 D(G(z)): 0.1440 / 0.3494\n",
            "[18/1001][200/600] Loss_D: 0.2304 Loss_G: 4.8112 D(x): 0.9776 D(G(z)): 0.1700 / 0.0140\n",
            "[18/1001][300/600] Loss_D: 0.1469 Loss_G: 4.2943 D(x): 0.9658 D(G(z)): 0.1004 / 0.0209\n",
            "[18/1001][400/600] Loss_D: 0.1292 Loss_G: 2.9528 D(x): 0.9213 D(G(z)): 0.0372 / 0.0723\n",
            "[18/1001][500/600] Loss_D: 0.2348 Loss_G: 4.9214 D(x): 0.9610 D(G(z)): 0.1612 / 0.0122\n",
            "[19/1001][0/600] Loss_D: 0.1203 Loss_G: 3.7165 D(x): 0.9456 D(G(z)): 0.0591 / 0.0358\n",
            "[19/1001][100/600] Loss_D: 0.0898 Loss_G: 3.9285 D(x): 0.9465 D(G(z)): 0.0317 / 0.0305\n",
            "[19/1001][200/600] Loss_D: 0.3112 Loss_G: 4.5725 D(x): 0.9647 D(G(z)): 0.2208 / 0.0163\n",
            "[19/1001][300/600] Loss_D: 1.0803 Loss_G: 1.4510 D(x): 0.6480 D(G(z)): 0.4213 / 0.2728\n",
            "[19/1001][400/600] Loss_D: 0.3083 Loss_G: 2.1736 D(x): 0.7913 D(G(z)): 0.0466 / 0.1570\n",
            "[19/1001][500/600] Loss_D: 1.0262 Loss_G: 0.7721 D(x): 0.5419 D(G(z)): 0.2214 / 0.5157\n",
            "[20/1001][0/600] Loss_D: 1.2378 Loss_G: 1.3025 D(x): 0.4510 D(G(z)): 0.2557 / 0.3217\n",
            "[20/1001][100/600] Loss_D: 0.1216 Loss_G: 4.0525 D(x): 0.9732 D(G(z)): 0.0854 / 0.0263\n",
            "[20/1001][200/600] Loss_D: 0.3601 Loss_G: 1.9681 D(x): 0.7299 D(G(z)): 0.0035 / 0.1884\n",
            "[20/1001][300/600] Loss_D: 0.0416 Loss_G: 5.1413 D(x): 0.9746 D(G(z)): 0.0152 / 0.0099\n",
            "[20/1001][400/600] Loss_D: 0.3789 Loss_G: 3.1088 D(x): 0.7893 D(G(z)): 0.1016 / 0.0760\n",
            "[20/1001][500/600] Loss_D: 0.8641 Loss_G: 1.8042 D(x): 0.7378 D(G(z)): 0.3574 / 0.2248\n",
            "[21/1001][0/600] Loss_D: 0.6760 Loss_G: 0.9703 D(x): 0.5542 D(G(z)): 0.0031 / 0.4405\n",
            "[21/1001][100/600] Loss_D: 0.1336 Loss_G: 3.3748 D(x): 0.9641 D(G(z)): 0.0846 / 0.0491\n",
            "[21/1001][200/600] Loss_D: 0.1490 Loss_G: 2.9687 D(x): 0.9080 D(G(z)): 0.0415 / 0.0752\n",
            "[21/1001][300/600] Loss_D: 0.2594 Loss_G: 1.1357 D(x): 0.8309 D(G(z)): 0.0493 / 0.3870\n",
            "[21/1001][400/600] Loss_D: 0.1020 Loss_G: 3.4977 D(x): 0.9485 D(G(z)): 0.0443 / 0.0441\n",
            "[21/1001][500/600] Loss_D: 0.1991 Loss_G: 3.8381 D(x): 0.9492 D(G(z)): 0.1228 / 0.0323\n",
            "[22/1001][0/600] Loss_D: 0.0544 Loss_G: 4.6254 D(x): 0.9836 D(G(z)): 0.0361 / 0.0162\n",
            "[22/1001][100/600] Loss_D: 0.4387 Loss_G: 2.1342 D(x): 0.7748 D(G(z)): 0.1325 / 0.1609\n",
            "[22/1001][200/600] Loss_D: 0.8749 Loss_G: 2.2918 D(x): 0.7249 D(G(z)): 0.3352 / 0.1347\n",
            "[22/1001][300/600] Loss_D: 0.6861 Loss_G: 1.3623 D(x): 0.6065 D(G(z)): 0.0954 / 0.3211\n",
            "[22/1001][400/600] Loss_D: 0.2322 Loss_G: 2.8199 D(x): 0.8762 D(G(z)): 0.0815 / 0.0886\n",
            "[22/1001][500/600] Loss_D: 0.2254 Loss_G: 2.4589 D(x): 0.8491 D(G(z)): 0.0415 / 0.1206\n",
            "[23/1001][0/600] Loss_D: 1.9636 Loss_G: 17.9246 D(x): 0.9994 D(G(z)): 0.7315 / 0.0000\n",
            "[23/1001][100/600] Loss_D: 0.4385 Loss_G: 2.6039 D(x): 0.7508 D(G(z)): 0.1029 / 0.1176\n",
            "[23/1001][200/600] Loss_D: 0.2021 Loss_G: 3.3516 D(x): 0.9384 D(G(z)): 0.1168 / 0.0592\n",
            "[23/1001][300/600] Loss_D: 0.4114 Loss_G: 2.4125 D(x): 0.8581 D(G(z)): 0.2040 / 0.1148\n",
            "[23/1001][400/600] Loss_D: 0.3054 Loss_G: 2.8497 D(x): 0.8921 D(G(z)): 0.1502 / 0.0835\n",
            "[23/1001][500/600] Loss_D: 1.4574 Loss_G: 1.3349 D(x): 0.3265 D(G(z)): 0.0507 / 0.3549\n",
            "[24/1001][0/600] Loss_D: 0.0457 Loss_G: 4.7772 D(x): 0.9701 D(G(z)): 0.0146 / 0.0127\n",
            "[24/1001][100/600] Loss_D: 0.4711 Loss_G: 2.0819 D(x): 0.8127 D(G(z)): 0.2108 / 0.1584\n",
            "[24/1001][200/600] Loss_D: 0.1419 Loss_G: 4.0652 D(x): 0.9741 D(G(z)): 0.1049 / 0.0221\n",
            "[24/1001][300/600] Loss_D: 0.0429 Loss_G: 4.7466 D(x): 0.9859 D(G(z)): 0.0279 / 0.0129\n",
            "[24/1001][400/600] Loss_D: 0.2519 Loss_G: 5.6004 D(x): 0.9916 D(G(z)): 0.1961 / 0.0052\n",
            "[24/1001][500/600] Loss_D: 0.4617 Loss_G: 2.8148 D(x): 0.8481 D(G(z)): 0.2293 / 0.0807\n",
            "[25/1001][0/600] Loss_D: 0.7215 Loss_G: 2.5914 D(x): 0.7982 D(G(z)): 0.3339 / 0.1063\n",
            "[25/1001][100/600] Loss_D: 0.0953 Loss_G: 3.8857 D(x): 0.9771 D(G(z)): 0.0668 / 0.0303\n",
            "[25/1001][200/600] Loss_D: 0.3198 Loss_G: 3.5406 D(x): 0.9505 D(G(z)): 0.2175 / 0.0374\n",
            "[25/1001][300/600] Loss_D: 0.2335 Loss_G: 2.3282 D(x): 0.8610 D(G(z)): 0.0673 / 0.1358\n",
            "[25/1001][400/600] Loss_D: 0.0624 Loss_G: 3.9341 D(x): 0.9792 D(G(z)): 0.0391 / 0.0293\n",
            "[25/1001][500/600] Loss_D: 0.0375 Loss_G: 4.9952 D(x): 0.9869 D(G(z)): 0.0235 / 0.0106\n",
            "[26/1001][0/600] Loss_D: 1.1496 Loss_G: 1.2283 D(x): 0.7041 D(G(z)): 0.4724 / 0.3352\n",
            "[26/1001][100/600] Loss_D: 0.4858 Loss_G: 2.7993 D(x): 0.9033 D(G(z)): 0.2876 / 0.0822\n",
            "[26/1001][200/600] Loss_D: 0.3502 Loss_G: 7.1472 D(x): 0.9878 D(G(z)): 0.2582 / 0.0012\n",
            "[26/1001][300/600] Loss_D: 0.5218 Loss_G: 3.3125 D(x): 0.8574 D(G(z)): 0.2664 / 0.0544\n",
            "[26/1001][400/600] Loss_D: 0.1676 Loss_G: 3.4914 D(x): 0.8695 D(G(z)): 0.0214 / 0.0490\n",
            "[26/1001][500/600] Loss_D: 0.0334 Loss_G: 4.8095 D(x): 0.9786 D(G(z)): 0.0113 / 0.0127\n",
            "[27/1001][0/600] Loss_D: 2.5555 Loss_G: 18.6000 D(x): 1.0000 D(G(z)): 0.8600 / 0.0000\n",
            "[27/1001][100/600] Loss_D: 0.6172 Loss_G: 1.0428 D(x): 0.6517 D(G(z)): 0.1165 / 0.4045\n",
            "[27/1001][200/600] Loss_D: 0.8744 Loss_G: 2.1871 D(x): 0.7518 D(G(z)): 0.3744 / 0.1574\n",
            "[27/1001][300/600] Loss_D: 0.2345 Loss_G: 2.0993 D(x): 0.8379 D(G(z)): 0.0371 / 0.1677\n",
            "[27/1001][400/600] Loss_D: 1.3454 Loss_G: 0.9392 D(x): 0.4619 D(G(z)): 0.3438 / 0.4311\n",
            "[27/1001][500/600] Loss_D: 0.0985 Loss_G: 3.6554 D(x): 0.9573 D(G(z)): 0.0509 / 0.0405\n",
            "[28/1001][0/600] Loss_D: 0.2342 Loss_G: 2.8295 D(x): 0.9257 D(G(z)): 0.1333 / 0.0812\n",
            "[28/1001][100/600] Loss_D: 0.1598 Loss_G: 2.9600 D(x): 0.9354 D(G(z)): 0.0812 / 0.0724\n",
            "[28/1001][200/600] Loss_D: 0.1952 Loss_G: 3.9636 D(x): 0.9721 D(G(z)): 0.1454 / 0.0261\n",
            "[28/1001][300/600] Loss_D: 0.0569 Loss_G: 5.5232 D(x): 0.9946 D(G(z)): 0.0481 / 0.0062\n",
            "[28/1001][400/600] Loss_D: 0.0974 Loss_G: 3.3837 D(x): 0.9296 D(G(z)): 0.0214 / 0.0545\n",
            "[28/1001][500/600] Loss_D: 0.0465 Loss_G: 4.6975 D(x): 0.9809 D(G(z)): 0.0257 / 0.0155\n",
            "[29/1001][0/600] Loss_D: 0.1691 Loss_G: 9.0917 D(x): 0.9985 D(G(z)): 0.1446 / 0.0002\n",
            "[29/1001][100/600] Loss_D: 0.8036 Loss_G: 1.6930 D(x): 0.7497 D(G(z)): 0.3522 / 0.2167\n",
            "[29/1001][200/600] Loss_D: 0.5905 Loss_G: 1.3785 D(x): 0.7308 D(G(z)): 0.1982 / 0.2962\n",
            "[29/1001][300/600] Loss_D: 1.1505 Loss_G: 0.2722 D(x): 0.4028 D(G(z)): 0.0566 / 0.7908\n",
            "[29/1001][400/600] Loss_D: 0.4196 Loss_G: 2.6514 D(x): 0.7067 D(G(z)): 0.0126 / 0.1054\n",
            "[29/1001][500/600] Loss_D: 0.1290 Loss_G: 3.6611 D(x): 0.9399 D(G(z)): 0.0608 / 0.0391\n",
            "[30/1001][0/600] Loss_D: 0.0531 Loss_G: 4.4457 D(x): 0.9807 D(G(z)): 0.0321 / 0.0191\n",
            "[30/1001][100/600] Loss_D: 0.0295 Loss_G: 4.3809 D(x): 0.9833 D(G(z)): 0.0123 / 0.0179\n",
            "[30/1001][200/600] Loss_D: 1.0871 Loss_G: 9.7521 D(x): 0.9959 D(G(z)): 0.5854 / 0.0001\n",
            "[30/1001][300/600] Loss_D: 0.0998 Loss_G: 3.9386 D(x): 0.9134 D(G(z)): 0.0049 / 0.0339\n",
            "[30/1001][400/600] Loss_D: 0.8496 Loss_G: 3.1555 D(x): 0.8977 D(G(z)): 0.4616 / 0.0637\n",
            "[30/1001][500/600] Loss_D: 0.9273 Loss_G: 1.3242 D(x): 0.5915 D(G(z)): 0.2632 / 0.3099\n",
            "[31/1001][0/600] Loss_D: 1.1269 Loss_G: 1.3463 D(x): 0.5386 D(G(z)): 0.3232 / 0.3113\n",
            "[31/1001][100/600] Loss_D: 1.1086 Loss_G: 1.5209 D(x): 0.6751 D(G(z)): 0.4472 / 0.2562\n",
            "[31/1001][200/600] Loss_D: 0.2255 Loss_G: 3.3386 D(x): 0.8883 D(G(z)): 0.0917 / 0.0500\n",
            "[31/1001][300/600] Loss_D: 0.8744 Loss_G: 1.2006 D(x): 0.5835 D(G(z)): 0.2321 / 0.3456\n",
            "[31/1001][400/600] Loss_D: 0.6879 Loss_G: 2.1401 D(x): 0.8955 D(G(z)): 0.3968 / 0.1528\n",
            "[31/1001][500/600] Loss_D: 0.0640 Loss_G: 3.7094 D(x): 0.9726 D(G(z)): 0.0347 / 0.0368\n",
            "[32/1001][0/600] Loss_D: 0.0502 Loss_G: 4.4208 D(x): 0.9603 D(G(z)): 0.0088 / 0.0182\n",
            "[32/1001][100/600] Loss_D: 0.6367 Loss_G: 1.7468 D(x): 0.7064 D(G(z)): 0.2084 / 0.2167\n",
            "[32/1001][200/600] Loss_D: 0.2658 Loss_G: 3.5568 D(x): 0.8431 D(G(z)): 0.0750 / 0.0426\n",
            "[32/1001][300/600] Loss_D: 1.0732 Loss_G: 1.1697 D(x): 0.7736 D(G(z)): 0.4904 / 0.3560\n",
            "[32/1001][400/600] Loss_D: 0.0932 Loss_G: 3.8055 D(x): 0.9285 D(G(z)): 0.0146 / 0.0342\n",
            "[32/1001][500/600] Loss_D: 0.0385 Loss_G: 4.5294 D(x): 0.9853 D(G(z)): 0.0229 / 0.0166\n",
            "[33/1001][0/600] Loss_D: 1.6593 Loss_G: 4.1621 D(x): 0.6763 D(G(z)): 0.5279 / 0.0255\n",
            "[33/1001][100/600] Loss_D: 0.0541 Loss_G: 4.3343 D(x): 0.9635 D(G(z)): 0.0160 / 0.0199\n",
            "[33/1001][200/600] Loss_D: 9.1180 Loss_G: 3.9917 D(x): 0.0002 D(G(z)): 0.0000 / 0.0298\n",
            "[33/1001][300/600] Loss_D: 0.5221 Loss_G: 2.7804 D(x): 0.9392 D(G(z)): 0.3150 / 0.0951\n",
            "[33/1001][400/600] Loss_D: 0.2941 Loss_G: 4.6355 D(x): 0.9623 D(G(z)): 0.2068 / 0.0154\n",
            "[33/1001][500/600] Loss_D: 0.0474 Loss_G: 4.0755 D(x): 0.9702 D(G(z)): 0.0165 / 0.0232\n",
            "[34/1001][0/600] Loss_D: 0.4750 Loss_G: 1.8887 D(x): 0.7270 D(G(z)): 0.1164 / 0.1840\n",
            "[34/1001][100/600] Loss_D: 0.0455 Loss_G: 4.1749 D(x): 0.9650 D(G(z)): 0.0092 / 0.0233\n",
            "[34/1001][200/600] Loss_D: 0.0522 Loss_G: 5.0105 D(x): 0.9831 D(G(z)): 0.0337 / 0.0112\n",
            "[34/1001][300/600] Loss_D: 0.0218 Loss_G: 5.3131 D(x): 0.9913 D(G(z)): 0.0127 / 0.0087\n",
            "[34/1001][400/600] Loss_D: 0.0214 Loss_G: 5.2204 D(x): 0.9908 D(G(z)): 0.0118 / 0.0106\n",
            "[34/1001][500/600] Loss_D: 1.4462 Loss_G: 1.2316 D(x): 0.6469 D(G(z)): 0.5817 / 0.3291\n",
            "[35/1001][0/600] Loss_D: 0.7194 Loss_G: 1.9538 D(x): 0.7755 D(G(z)): 0.3267 / 0.1726\n",
            "[35/1001][100/600] Loss_D: 0.4555 Loss_G: 3.4846 D(x): 0.9759 D(G(z)): 0.2979 / 0.0533\n",
            "[35/1001][200/600] Loss_D: 0.3000 Loss_G: 1.6093 D(x): 0.7698 D(G(z)): 0.0142 / 0.2689\n",
            "[35/1001][300/600] Loss_D: 0.0476 Loss_G: 4.4696 D(x): 0.9816 D(G(z)): 0.0272 / 0.0195\n",
            "[35/1001][400/600] Loss_D: 0.9891 Loss_G: 1.1533 D(x): 0.4996 D(G(z)): 0.1756 / 0.3594\n",
            "[35/1001][500/600] Loss_D: 0.4797 Loss_G: 3.0465 D(x): 0.8696 D(G(z)): 0.2586 / 0.0688\n",
            "[36/1001][0/600] Loss_D: 0.5818 Loss_G: 2.6586 D(x): 0.8856 D(G(z)): 0.3192 / 0.1004\n",
            "[36/1001][100/600] Loss_D: 0.0853 Loss_G: 3.6400 D(x): 0.9628 D(G(z)): 0.0445 / 0.0380\n",
            "[36/1001][200/600] Loss_D: 0.0567 Loss_G: 4.1054 D(x): 0.9781 D(G(z)): 0.0328 / 0.0249\n",
            "[36/1001][300/600] Loss_D: 0.0243 Loss_G: 4.9834 D(x): 0.9894 D(G(z)): 0.0133 / 0.0119\n",
            "[36/1001][400/600] Loss_D: 0.4670 Loss_G: 3.0384 D(x): 0.8548 D(G(z)): 0.2336 / 0.0690\n",
            "[36/1001][500/600] Loss_D: 0.5890 Loss_G: 1.9033 D(x): 0.7673 D(G(z)): 0.2413 / 0.1999\n",
            "[37/1001][0/600] Loss_D: 0.4498 Loss_G: 2.4983 D(x): 0.9099 D(G(z)): 0.2742 / 0.1063\n",
            "[37/1001][100/600] Loss_D: 0.0366 Loss_G: 4.2688 D(x): 0.9803 D(G(z)): 0.0161 / 0.0237\n",
            "[37/1001][200/600] Loss_D: 0.0240 Loss_G: 4.6710 D(x): 0.9887 D(G(z)): 0.0122 / 0.0168\n",
            "[37/1001][300/600] Loss_D: 0.1152 Loss_G: 8.4062 D(x): 0.9932 D(G(z)): 0.0947 / 0.0004\n",
            "[37/1001][400/600] Loss_D: 0.2463 Loss_G: 2.6103 D(x): 0.8543 D(G(z)): 0.0713 / 0.1028\n",
            "[37/1001][500/600] Loss_D: 0.0933 Loss_G: 3.2405 D(x): 0.9367 D(G(z)): 0.0199 / 0.0662\n",
            "[38/1001][0/600] Loss_D: 0.5853 Loss_G: 3.1795 D(x): 0.9391 D(G(z)): 0.3604 / 0.0615\n",
            "[38/1001][100/600] Loss_D: 0.0827 Loss_G: 4.4415 D(x): 0.9392 D(G(z)): 0.0166 / 0.0184\n",
            "[38/1001][200/600] Loss_D: 0.0498 Loss_G: 4.5542 D(x): 0.9743 D(G(z)): 0.0230 / 0.0176\n",
            "[38/1001][300/600] Loss_D: 0.0334 Loss_G: 5.4559 D(x): 0.9849 D(G(z)): 0.0177 / 0.0075\n",
            "[38/1001][400/600] Loss_D: 1.1504 Loss_G: 0.9783 D(x): 0.5703 D(G(z)): 0.4008 / 0.4086\n",
            "[38/1001][500/600] Loss_D: 1.0294 Loss_G: 1.7935 D(x): 0.7693 D(G(z)): 0.4806 / 0.2047\n",
            "[39/1001][0/600] Loss_D: 0.7629 Loss_G: 1.8557 D(x): 0.6695 D(G(z)): 0.2524 / 0.1907\n",
            "[39/1001][100/600] Loss_D: 0.5376 Loss_G: 3.1373 D(x): 0.8635 D(G(z)): 0.2897 / 0.0586\n",
            "[39/1001][200/600] Loss_D: 0.5976 Loss_G: 1.8914 D(x): 0.7521 D(G(z)): 0.2327 / 0.1993\n",
            "[39/1001][300/600] Loss_D: 6.9839 Loss_G: 4.8239 D(x): 0.0017 D(G(z)): 0.0001 / 0.0139\n",
            "[39/1001][400/600] Loss_D: 0.1291 Loss_G: 3.2079 D(x): 0.9251 D(G(z)): 0.0444 / 0.0639\n",
            "[39/1001][500/600] Loss_D: 0.0437 Loss_G: 4.2638 D(x): 0.9762 D(G(z)): 0.0187 / 0.0253\n",
            "[40/1001][0/600] Loss_D: 0.9420 Loss_G: 1.3686 D(x): 0.6997 D(G(z)): 0.4033 / 0.2798\n",
            "[40/1001][100/600] Loss_D: 0.2142 Loss_G: 3.6110 D(x): 0.9470 D(G(z)): 0.1342 / 0.0373\n",
            "[40/1001][200/600] Loss_D: 0.4139 Loss_G: 4.7338 D(x): 0.9704 D(G(z)): 0.2829 / 0.0127\n",
            "[40/1001][300/600] Loss_D: 0.0253 Loss_G: 4.5576 D(x): 0.9910 D(G(z)): 0.0158 / 0.0170\n",
            "[40/1001][400/600] Loss_D: 0.2551 Loss_G: 3.5112 D(x): 0.9638 D(G(z)): 0.1829 / 0.0424\n",
            "[40/1001][500/600] Loss_D: 0.0567 Loss_G: 4.0717 D(x): 0.9582 D(G(z)): 0.0129 / 0.0279\n",
            "[41/1001][0/600] Loss_D: 4.8917 Loss_G: 0.1301 D(x): 0.0190 D(G(z)): 0.0055 / 0.8962\n",
            "[41/1001][100/600] Loss_D: 0.3647 Loss_G: 2.8593 D(x): 0.8606 D(G(z)): 0.1712 / 0.0791\n",
            "[41/1001][200/600] Loss_D: 0.0463 Loss_G: 4.0636 D(x): 0.9780 D(G(z)): 0.0232 / 0.0254\n",
            "[41/1001][300/600] Loss_D: 0.0388 Loss_G: 4.6735 D(x): 0.9860 D(G(z)): 0.0237 / 0.0167\n",
            "[41/1001][400/600] Loss_D: 0.0286 Loss_G: 5.0119 D(x): 0.9916 D(G(z)): 0.0198 / 0.0103\n",
            "[41/1001][500/600] Loss_D: 0.0759 Loss_G: 4.4644 D(x): 0.9787 D(G(z)): 0.0495 / 0.0198\n",
            "[42/1001][0/600] Loss_D: 0.0247 Loss_G: 5.0299 D(x): 0.9946 D(G(z)): 0.0188 / 0.0109\n",
            "[42/1001][100/600] Loss_D: 0.0183 Loss_G: 5.4326 D(x): 0.9903 D(G(z)): 0.0084 / 0.0083\n",
            "[42/1001][200/600] Loss_D: 0.1504 Loss_G: 1.6930 D(x): 0.8715 D(G(z)): 0.0015 / 0.2463\n",
            "[42/1001][300/600] Loss_D: 0.0220 Loss_G: 5.4922 D(x): 0.9881 D(G(z)): 0.0097 / 0.0081\n",
            "[42/1001][400/600] Loss_D: 0.0176 Loss_G: 5.6186 D(x): 0.9947 D(G(z)): 0.0121 / 0.0060\n",
            "[42/1001][500/600] Loss_D: 0.4691 Loss_G: 1.9149 D(x): 0.7175 D(G(z)): 0.0956 / 0.1927\n",
            "[43/1001][0/600] Loss_D: 1.1974 Loss_G: 1.4696 D(x): 0.6888 D(G(z)): 0.4996 / 0.2721\n",
            "[43/1001][100/600] Loss_D: 0.1810 Loss_G: 3.5940 D(x): 0.9500 D(G(z)): 0.1074 / 0.0454\n",
            "[43/1001][200/600] Loss_D: 0.5618 Loss_G: 1.8723 D(x): 0.7182 D(G(z)): 0.1624 / 0.2031\n",
            "[43/1001][300/600] Loss_D: 0.6868 Loss_G: 1.9480 D(x): 0.7758 D(G(z)): 0.2899 / 0.1876\n",
            "[43/1001][400/600] Loss_D: 0.1122 Loss_G: 3.9792 D(x): 0.9359 D(G(z)): 0.0419 / 0.0300\n",
            "[43/1001][500/600] Loss_D: 0.0342 Loss_G: 4.9509 D(x): 0.9746 D(G(z)): 0.0080 / 0.0109\n",
            "[44/1001][0/600] Loss_D: 0.0163 Loss_G: 4.7746 D(x): 0.9942 D(G(z)): 0.0103 / 0.0134\n",
            "[44/1001][100/600] Loss_D: 0.1442 Loss_G: 3.7401 D(x): 0.8839 D(G(z)): 0.0112 / 0.0368\n",
            "[44/1001][200/600] Loss_D: 3.7549 Loss_G: 2.4061 D(x): 0.0448 D(G(z)): 0.0015 / 0.1486\n",
            "[44/1001][300/600] Loss_D: 0.0204 Loss_G: 5.1679 D(x): 0.9928 D(G(z)): 0.0129 / 0.0109\n",
            "[44/1001][400/600] Loss_D: 0.0225 Loss_G: 7.7209 D(x): 0.9989 D(G(z)): 0.0204 / 0.0012\n",
            "[44/1001][500/600] Loss_D: 0.0114 Loss_G: 6.3324 D(x): 0.9992 D(G(z)): 0.0106 / 0.0030\n",
            "[45/1001][0/600] Loss_D: 0.0098 Loss_G: 7.1109 D(x): 0.9998 D(G(z)): 0.0095 / 0.0020\n",
            "[45/1001][100/600] Loss_D: 0.0033 Loss_G: 7.4018 D(x): 0.9989 D(G(z)): 0.0023 / 0.0011\n",
            "[45/1001][200/600] Loss_D: 0.0025 Loss_G: 8.1874 D(x): 0.9984 D(G(z)): 0.0009 / 0.0006\n",
            "[45/1001][300/600] Loss_D: 0.0039 Loss_G: 7.4621 D(x): 0.9980 D(G(z)): 0.0017 / 0.0010\n",
            "[45/1001][400/600] Loss_D: 0.0013 Loss_G: 7.5734 D(x): 0.9999 D(G(z)): 0.0012 / 0.0008\n",
            "[45/1001][500/600] Loss_D: 0.0011 Loss_G: 7.6504 D(x): 0.9999 D(G(z)): 0.0010 / 0.0007\n",
            "[46/1001][0/600] Loss_D: 0.0012 Loss_G: 7.7578 D(x): 0.9997 D(G(z)): 0.0009 / 0.0007\n",
            "[46/1001][100/600] Loss_D: 0.0014 Loss_G: 7.6370 D(x): 0.9998 D(G(z)): 0.0012 / 0.0008\n",
            "[46/1001][200/600] Loss_D: 0.0012 Loss_G: 7.4627 D(x): 0.9999 D(G(z)): 0.0011 / 0.0008\n",
            "[46/1001][300/600] Loss_D: 0.0009 Loss_G: 7.6656 D(x): 0.9999 D(G(z)): 0.0008 / 0.0006\n",
            "[46/1001][400/600] Loss_D: 0.0009 Loss_G: 7.5094 D(x): 0.9999 D(G(z)): 0.0008 / 0.0006\n",
            "[46/1001][500/600] Loss_D: 0.0005 Loss_G: 7.9580 D(x): 1.0000 D(G(z)): 0.0005 / 0.0004\n",
            "[47/1001][0/600] Loss_D: 0.0004 Loss_G: 8.0990 D(x): 1.0000 D(G(z)): 0.0004 / 0.0004\n",
            "[47/1001][100/600] Loss_D: 0.0003 Loss_G: 8.5244 D(x): 1.0000 D(G(z)): 0.0003 / 0.0002\n",
            "[47/1001][200/600] Loss_D: 0.0006 Loss_G: 8.4812 D(x): 0.9998 D(G(z)): 0.0003 / 0.0003\n",
            "[47/1001][300/600] Loss_D: 0.0006 Loss_G: 8.1187 D(x): 0.9999 D(G(z)): 0.0005 / 0.0004\n",
            "[47/1001][400/600] Loss_D: 0.0004 Loss_G: 10.0235 D(x): 0.9996 D(G(z)): 0.0001 / 0.0001\n",
            "[47/1001][500/600] Loss_D: 0.0001 Loss_G: 9.6991 D(x): 1.0000 D(G(z)): 0.0001 / 0.0001\n",
            "[48/1001][0/600] Loss_D: 0.0005 Loss_G: 8.9642 D(x): 0.9998 D(G(z)): 0.0003 / 0.0002\n",
            "[48/1001][100/600] Loss_D: 0.0004 Loss_G: 9.3584 D(x): 0.9998 D(G(z)): 0.0002 / 0.0001\n",
            "[48/1001][200/600] Loss_D: 0.0002 Loss_G: 9.0703 D(x): 0.9999 D(G(z)): 0.0001 / 0.0001\n",
            "[48/1001][300/600] Loss_D: 0.0003 Loss_G: 9.3037 D(x): 0.9999 D(G(z)): 0.0002 / 0.0001\n",
            "[48/1001][400/600] Loss_D: 0.0019 Loss_G: 7.9968 D(x): 0.9984 D(G(z)): 0.0003 / 0.0004\n",
            "[48/1001][500/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[49/1001][0/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[49/1001][100/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[49/1001][200/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[49/1001][300/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[49/1001][400/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[49/1001][500/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[50/1001][0/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[50/1001][100/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[50/1001][200/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[50/1001][300/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[50/1001][400/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[50/1001][500/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[51/1001][0/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[51/1001][100/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[51/1001][200/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[51/1001][300/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[51/1001][400/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[51/1001][500/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[52/1001][0/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[52/1001][100/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[52/1001][200/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[52/1001][300/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[52/1001][400/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[52/1001][500/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[53/1001][0/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[53/1001][100/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[53/1001][200/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[53/1001][300/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[53/1001][400/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[53/1001][500/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[54/1001][0/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[54/1001][100/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[54/1001][200/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[54/1001][300/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[54/1001][400/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[54/1001][500/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[55/1001][0/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[55/1001][100/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[55/1001][200/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[55/1001][300/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[55/1001][400/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[55/1001][500/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[56/1001][0/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[56/1001][100/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[56/1001][200/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[56/1001][300/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[56/1001][400/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[56/1001][500/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[57/1001][0/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[57/1001][100/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[57/1001][200/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[57/1001][300/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[57/1001][400/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[57/1001][500/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[58/1001][0/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[58/1001][100/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n",
            "[58/1001][200/600] Loss_D: 27.6310 Loss_G: 0.0000 D(x): 1.0000 D(G(z)): 1.0000 / 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-352b2fd01d34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_label\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# fake labels are real for generator cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0merrG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0merrG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-352b2fd01d34>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}